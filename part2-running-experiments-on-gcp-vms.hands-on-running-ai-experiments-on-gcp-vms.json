{"version":3,"kind":"Article","sha256":"db9e022703798eb6d0481453799badb9d8ee3004395b845fb31e9b5012091e6d","slug":"part2-running-experiments-on-gcp-vms.hands-on-running-ai-experiments-on-gcp-vms","location":"/part2-running-experiments-on-gcp-vms/01-hands-on-running-ai-experiments-on-gcp-vms.md","dependencies":[],"frontmatter":{"title":"Hands-On 01: Fine-tuning a Small Language Model (Gemma 3 1B) on a GCP VM","content_includes_title":false,"authors":[{"id":"AIMS TtT Team","name":"AIMS TtT Team"}],"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true}},"github":"https://github.com/rexsimiloluwa/aims-ai-gcp-tutorial","keywords":["GCP","AI","GPU","Machine Learning","Research","Experiments","MLOps"],"numbering":{"title":{"offset":1}},"source_url":"https://github.com/rexsimiloluwa/aims-ai-gcp-tutorial/blob/main/part2-running-experiments-on-gcp-vms/01-hands-on-running-ai-experiments-on-gcp-vms.md","edit_url":"https://github.com/rexsimiloluwa/aims-ai-gcp-tutorial/edit/main/part2-running-experiments-on-gcp-vms/01-hands-on-running-ai-experiments-on-gcp-vms.md","thumbnail":"/build/create_new_project_w-1654c90f25a039c9cd3dea119a07f7d2.png","exports":[{"format":"md","filename":"01-hands-on-running-ai-experiments-on-gcp-vms.md","url":"/build/01-hands-on-running--3cd0a9338044283907e79e47e5e30ac1.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this hands-on session, we will fine-tune ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"iCSrHmbRej"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Gemma 3 1B","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tqFpsJvN7d"}],"key":"L5sIkiuI39"},{"type":"text","value":" (a small language model with 1 billion parameters) on the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VO7wTOT4IV"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Dolly-15k","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MQBunjM8ZS"}],"key":"qCnLgCicGG"},{"type":"text","value":" instruction dataset using ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"S4Se9ymvUl"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"LoRA (Low-Rank Adaptation)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AVEWDUrsYf"}],"key":"MO2QOdDxr5"},{"type":"text","value":", track our experiments with ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XVajpRaktd"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Weights & Biases","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PFKByYVIVL"}],"key":"Z3up7KGj5n"},{"type":"text","value":", and persist outputs and model artifacts to ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nJXMNkeLSD"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Google Cloud Storage","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eQ7AZK4IGr"}],"key":"iJ5Kdkdahj"},{"type":"text","value":".","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FnumZf1kd3"}],"key":"wm49zDRzBR"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Overview","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"AojVWkoL0M"}],"identifier":"overview","label":"Overview","html_id":"overview","implicit":true,"key":"owdG4Gqj4j"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"By the end of this hands-on session, you will have:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"yUSPYVrBpY"}],"key":"zmpmCTq3hL"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Provisioned an L4 GPU VM using the Compute Engine service via ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"fbHJ0NqHMe"},{"type":"inlineCode","value":"gcloud","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"MXD01YEU4u"},{"type":"text","value":" CLI","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"Opker5qH83"}],"key":"HidBg5uod8"}],"key":"zKe2H3FdDU"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Set up a Python environment using ","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"d82tkhaebr"},{"type":"inlineCode","value":"uv","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"zZmkCJSDRF"}],"key":"LaXLctYuIK"}],"key":"qLELRSAd83"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Cloned the experiment repository from GitHub","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"WfkFQrlSfv"}],"key":"HfDQr5nQiN"}],"key":"TYYfhu9ep6"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Run the scripts to fine-tune Gemma 3 1B using LoRA on the Dolly 15k dataset","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"y9yO4R9rb2"}],"key":"KxoKixwo09"}],"key":"nyZWJc2Zmd"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Created persistent SSH sessions using ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"TQP5OTfBAE"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"ck8riwibGE"}],"key":"ifENXN5R7H"}],"key":"LDAP7NzhHe"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Learnt how to monitor training in real-time using Weights & Biases","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"h7VnKHASpD"}],"key":"aNiYKseOyq"}],"key":"QWvMcmu2Ia"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Persisted outputs and model artifacts to Google Cloud Storage (GCS)","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"OAm9EgStbY"}],"key":"CfmzRBLcRr"}],"key":"Y4WBFL4TK7"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Cleaned up all resources to avoid unnecessary charges","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"NuNldI3soI"}],"key":"mAwbd5CZtw"}],"key":"kO2TGdExOo"}],"key":"yyxOtRHOsK"},{"type":"heading","depth":2,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Background","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"AOBn8DFEFY"}],"identifier":"background","label":"Background","html_id":"background","implicit":true,"key":"bhNvTkbCeF"},{"type":"details","children":[{"type":"summary","children":[{"type":"text","value":"Click here for more background information about this hands-on session.","key":"wlHo29BeL5"}],"key":"QWe16qOepx"},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why This Experiment?","key":"Qhofz4MHcP"}],"identifier":"why-this-experiment","label":"Why This Experiment?","html_id":"why-this-experiment","implicit":true,"key":"KFF7zKkCti"},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Fine-tuning takes an already capable model and adapts it to a specific task at a fraction of the cost of training from scratch, which is how most real-world LLM applications are built.","key":"U9M78uHzYA"}],"key":"tP3CCt0jty"}],"key":"VgONEJBs3X"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We use Gemma 3 1B because fine-tuning a model at this scale of one billion parameters introduces you to the practical realities of running large model training on cloud infrastructure, including GPU memory constraints, checkpoint management, and experiment tracking.","key":"Zuzk10ixI0"}],"key":"lVB0aFeIzu"}],"key":"QwgKWuTz2v"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"At 1B parameters, Gemma is large enough to produce meaningful, coherent responses and representative of the models used in real applications, but small enough to fine-tune on a single L4 GPU in under 30 minutes, making it a practical starting point.","key":"uiHMFpG7We"}],"key":"OZ7myM5Muw"}],"key":"zwRKpeYPv0"}],"key":"g2XZOGqAHA"},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why LoRA?","key":"gQcWsXlBmr"}],"identifier":"why-lora","label":"Why LoRA?","html_id":"why-lora","implicit":true,"key":"lMFbBNJk3Y"},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Even at 1 Billion parameters, fully fine-tuning Gemma 1B would require updating every weight in the model on every training step, which is memory-intensive and slow on a single GPU.","key":"AzPU3dOaxO"}],"key":"UlHCaZj5oQ"}],"key":"noGCkV4yh0"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"LoRA solves this by freezing the original model weights and injecting small trainable matrices into specific layers, training less than the full parameters while still achieving meaningful adaptation.","key":"Rfy49f87Nz"}],"key":"uwVEY7WiB9"}],"key":"BDDWEOzaIU"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"The key hyperparameter is the rank (","key":"Gmq7gkIpzd"},{"type":"inlineCode","value":"r","key":"O4ImzvI8Mp"},{"type":"text","value":"), which controls the size of these trainable matrices. A higher rank means more expressive power but more memory and compute.","key":"WoLXxWkYRL"}],"key":"Qiuoq1cm3h"}],"key":"OdKnT6pzly"}],"key":"W1FrZB44bO"},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why Dolly-15k?","key":"DqbJO6svWP"}],"identifier":"why-dolly-15k","label":"Why Dolly-15k?","html_id":"why-dolly-15k","implicit":true,"key":"JYJKWhX5wE"},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Dolly-15k is an open-source instruction-following dataset created by Databricks, containing 15,000 human-generated prompt-response pairs.","key":"VTe7z978Y1"}],"key":"vybKoWDJNO"}],"key":"yr1SGv9O0S"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"It covers a wide range of tasks including question answering, summarization, classification, and creative writing.","key":"bReVZDTOjN"}],"key":"JDj7sx2CCn"}],"key":"yuQFEqa5Cx"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We use it because it is freely available, well-structured, and a standard dataset for instruction fine-tuning, making results easy to compare and reproduce.","key":"Juf20l9IE9"}],"key":"NTquFvamKU"}],"key":"C9TN8vNuzA"}],"key":"D9VtDOhe8f"},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why ","key":"X2d8fdZotA"},{"type":"inlineCode","value":"tmux","key":"LAZUOZcEps"},{"type":"text","value":"?","key":"XgHViQpJ9M"}],"identifier":"why-tmux","label":"Why tmux?","html_id":"why-tmux","implicit":true,"key":"zWkWRB2ycm"},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Training a 1 Billion parameter model takes time. Keeping an SSH connection open for the entire duration is fragile and impractical.","key":"cDqTggrAn8"}],"key":"cLfIOQgXeU"}],"key":"itUNzE5QMa"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"If your SSH session disconnects, any process running in that terminal is killed, meaning your training run is lost and you have to start over.","key":"GRguiJUk48"}],"key":"IdolJUH4Jh"}],"key":"sy1BDR3VyN"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"tmux","key":"NIPzSFgZIM"},{"type":"text","value":" keeps your training process running on the VM independently of your SSH connection, so a dropped connection does not affect the job.","key":"iaHzil5gKL"}],"key":"FuOzNpIzts"}],"key":"qKf6gmCcL8"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"It also means you can disconnect intentionally, close your laptop, and reconnect later to check progress without interrupting anything.","key":"znirWDxrRX"}],"key":"X952x2w4QW"}],"key":"P5p9Rkg1K3"}],"key":"xOULcjgEAg"},{"type":"heading","depth":3,"children":[{"type":"text","value":"Why Weights & Biases?","key":"OP1pwIFDvg"}],"identifier":"why-weights-biases","label":"Why Weights & Biases?","html_id":"why-weights-biases","implicit":true,"key":"dU1fCsFQO1"},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Training runs on a remote VM, so you need a way to monitor progress without staying connected via SSH.","key":"vKCE2bZoz2"}],"key":"pqDo0ATACG"}],"key":"n7cJz53PvG"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"WandB logs metrics like loss, learning rate, and gradient norms in real time and makes them accessible from any browser, meaning you can close your laptop and check the dashboard later.","key":"zR7n7Qk8an"}],"key":"uNvnSOZ3VE"}],"key":"trboWyDjj8"},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"It also keeps a history of every run, making it easy to compare experiments and share results with others.","key":"zdD8HpEjfk"}],"key":"Gi8JV1bQL1"}],"key":"rkyC6SLBJp"}],"key":"bDFBWvhZdJ"}],"key":"Taz9XV2g93"},{"type":"heading","depth":2,"position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Step 1: Create the VM","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"wPnDhDtcZa"}],"identifier":"step-1-create-the-vm","label":"Step 1: Create the VM","html_id":"step-1-create-the-vm","implicit":true,"key":"RJgQ6JqmaT"},{"type":"paragraph","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Create a new shell script file called ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"KasUwCc8BX"},{"type":"inlineCode","value":"create_vm.sh","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"nddZNTAI2M"},{"type":"text","value":" and copy the script below into it. Before running the script, update the ","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"F1EmUjMdC5"},{"type":"inlineCode","value":"AIMSUSERNAME","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"yqMOYhLXq2"},{"type":"text","value":" variable at the top to your username:","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"XcD0yQz3Yp"}],"key":"Zo6auqxBdw"},{"type":"code","lang":"bash","value":"nano create_vm.sh","key":"vH3OPFxNQY"},{"type":"paragraph","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"Paste the following script:","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"faKrm63OAE"}],"key":"FwRR5d037s"},{"type":"code","lang":"bash","value":"#!/bin/bash\n\nexport AIMSUSERNAME=\"<your_aims_username>\" # Change this to your own username\nexport REGION=\"europe-west4\"\nexport ZONE=\"europe-west4-a\"\n\n# Create VPC if it doesn't exist\nif ! gcloud compute networks describe ${AIMSUSERNAME}-vpc &>/dev/null; then\n    gcloud compute networks create ${AIMSUSERNAME}-vpc --subnet-mode=auto\nelse\n    echo \"VPC ${AIMSUSERNAME}-vpc already exists, skipping.\"\nfi\n\n# Create firewall rule if it doesn't exist\nif ! gcloud compute firewall-rules describe ${AIMSUSERNAME}-fw-ssh &>/dev/null; then\n    gcloud compute firewall-rules create ${AIMSUSERNAME}-fw-ssh \\\n        --network=${AIMSUSERNAME}-vpc \\\n        --allow=tcp:22\nelse\n    echo \"Firewall rule ${AIMSUSERNAME}-fw-ssh already exists, skipping.\"\nfi\n\n# Create Cloud Router if it doesn't exist\nif ! gcloud compute routers describe ${AIMSUSERNAME}-router-${REGION} --region=${REGION} &>/dev/null; then\n    gcloud compute routers create ${AIMSUSERNAME}-router-${REGION} \\\n        --network=${AIMSUSERNAME}-vpc \\\n        --region=${REGION}\nelse\n    echo \"Router ${AIMSUSERNAME}-router-${REGION} already exists, skipping.\"\nfi\n\n# Create NAT if it doesn't exist\nif ! gcloud compute routers nats describe ${AIMSUSERNAME}-nat-config \\\n    --router=${AIMSUSERNAME}-router-${REGION} \\\n    --region=${REGION} &>/dev/null; then\n    gcloud compute routers nats create ${AIMSUSERNAME}-nat-config \\\n        --router-region=${REGION} \\\n        --router=${AIMSUSERNAME}-router-${REGION} \\\n        --nat-all-subnet-ip-ranges \\\n        --auto-allocate-nat-external-ips\nelse\n    echo \"NAT ${AIMSUSERNAME}-nat-config already exists, skipping.\"\nfi\n\nexport VM_NAME=\"${AIMSUSERNAME}-l4-vm\"\n\ngcloud compute instances create ${VM_NAME} \\\n    --zone=${ZONE} \\\n    --machine-type=g2-standard-4 \\\n    --accelerator=\"type=nvidia-l4,count=1\" \\\n    --image-family=common-cu128-ubuntu-2204-nvidia-570 \\\n    --image-project=deeplearning-platform-release \\\n    --maintenance-policy=TERMINATE \\\n    --network=${AIMSUSERNAME}-vpc \\\n    --scopes=storage-full,cloud-platform","key":"PFoNIIoo4Z"},{"type":"paragraph","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"children":[{"type":"text","value":"Then save and run the script:","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"key":"efKiqTVq2F"}],"key":"DUCCiwgMHe"},{"type":"code","lang":"bash","value":"chmod +x create_vm.sh\n./create_vm.sh","key":"U9hph3vBU2"},{"type":"paragraph","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"children":[{"type":"text","value":"The script creates all necessary networking infrastructure (VPC, firewall, router, NAT) and provisions a VM with an NVIDIA L4 GPU.","position":{"start":{"line":130,"column":1},"end":{"line":130,"column":1}},"key":"AboDpYxj6l"}],"key":"a0ITYl381G"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"fmGBZBmSJw"}],"key":"zdSWBM9z9z"},{"type":"paragraph","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"text","value":"Notice the ","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"mBBJqrLodH"},{"type":"inlineCode","value":"--scopes=storage-full,cloud-platform","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"SQ8849ANba"},{"type":"text","value":" flag in the ","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"Tt4u8GoBxm"},{"type":"inlineCode","value":"gcloud compute instances create","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"qR6BCFCt8G"},{"type":"text","value":" command for creating the VM. This gives the VM permission to read from and write to GCS, which we will need later when uploading the dataset and syncing experiment outputs and model artifacts.","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"BCzRvhuATP"}],"key":"nDTf984L8h"}],"key":"p2J76VyVSn"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"yoFb9wC1tM"}],"key":"VdDoblOypD"},{"type":"paragraph","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"text","value":"If you see an error like ","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"VOqSwou71N"},{"type":"inlineCode","value":"The zone does not have enough resources available","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"RtcTwBHK7v"},{"type":"text","value":", the NVIDIA L4 GPU is out of stock in that zone. Try changing ","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"JWQspDaq9F"},{"type":"inlineCode","value":"ZONE","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"h8NAydOYdG"},{"type":"text","value":" in the script to a nearby zone like europe-west4-b or europe-west4-c or changing the region ","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"kWfphz4gd7"},{"type":"inlineCode","value":"REGION","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"JI5UySuJTl"},{"type":"text","value":" in the script to another region e.g. ","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"BVLxueEhG9"},{"type":"inlineCode","value":"us-central1","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"kHiDeEKkFM"},{"type":"text","value":".","position":{"start":{"line":137,"column":1},"end":{"line":137,"column":1}},"key":"y1s68VEtcF"}],"key":"zH8DkIGOlA"}],"key":"yoKdSPwY5J"},{"type":"paragraph","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"children":[{"type":"text","value":"Then verify the VM is running:","position":{"start":{"line":140,"column":1},"end":{"line":140,"column":1}},"key":"V2Q5If7pul"}],"key":"ssPmsE2B69"},{"type":"code","lang":"bash","value":"gcloud compute instances list","key":"FJfmCew1DR"},{"type":"heading","depth":2,"position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"Step 2: SSH into the VM","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"cSqBUjIZhq"}],"identifier":"step-2-ssh-into-the-vm","label":"Step 2: SSH into the VM","html_id":"step-2-ssh-into-the-vm","implicit":true,"key":"mrDSNbZZbP"},{"type":"code","lang":"bash","value":"gcloud compute ssh <YOUR_AIMS_USERNAME>-l4-vm --zone=europe-west4-a --tunnel-through-iap","key":"XUgCiTHaUC"},{"type":"paragraph","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"children":[{"type":"text","value":"Replace ","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"Y2DsNV4s9A"},{"type":"inlineCode","value":"<YOUR_AIMS_USERNAME>","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"bAQSfG5y5A"},{"type":"text","value":" and the ","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"yDEktLfUMA"},{"type":"inlineCode","value":"--zone","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"jVU5jIKToR"},{"type":"text","value":" flag with the values you used when running the script.","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"WjfkDjsujR"}],"key":"pHXZUfMyGm"},{"type":"paragraph","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"children":[{"type":"text","value":"When you have successfully “SSH-ed” into your server, verify the GPU is available.","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"key":"eMDSROsxos"}],"key":"bml4bMBv1K"},{"type":"code","lang":"bash","value":"nvidia-smi","key":"dHAchNukR0"},{"type":"paragraph","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"children":[{"type":"text","value":"You should see the NVIDIA L4 with 24GB VRAM listed. All subsequent commands are run inside this SSH session.","position":{"start":{"line":160,"column":1},"end":{"line":160,"column":1}},"key":"vmbAWqYwRa"}],"key":"zof3QKmCyh"},{"type":"heading","depth":2,"position":{"start":{"line":162,"column":1},"end":{"line":162,"column":1}},"children":[{"type":"text","value":"Step 3: Install ","position":{"start":{"line":162,"column":1},"end":{"line":162,"column":1}},"key":"qxC8eUa33a"},{"type":"inlineCode","value":"uv","position":{"start":{"line":162,"column":1},"end":{"line":162,"column":1}},"key":"F9LY0NERXN"}],"identifier":"step-3-install-uv","label":"Step 3: Install uv","html_id":"step-3-install-uv","implicit":true,"key":"xrCx8X9lOT"},{"type":"paragraph","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"children":[{"type":"inlineCode","value":"uv","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"MhaouF399c"},{"type":"text","value":" is a fast Python package and project manager that handles creating virtual environments, installing dependencies, and locking package versions. We use it because it guarantees the exact same environment can be recreated on any machine with a single command.","position":{"start":{"line":164,"column":1},"end":{"line":164,"column":1}},"key":"BioAbUwuri"}],"key":"d0LcDhDvPd"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"UWlutJXm9w"}],"key":"OYWQ43E3DX"},{"type":"paragraph","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"children":[{"type":"text","value":"The VM image we provisioned already comes with Python pre-installed, so we do not need to set up Python manually. ","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"WDYRLOtE9b"},{"type":"inlineCode","value":"uv","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"ha3Xvv5TPu"},{"type":"text","value":" will use the existing Python installation and manage everything else for us.","position":{"start":{"line":167,"column":1},"end":{"line":167,"column":1}},"key":"olyRgo3gEE"}],"key":"a4vc20XvWo"}],"key":"xhGAPDLKYm"},{"type":"paragraph","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"children":[{"type":"strong","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"children":[{"type":"text","value":"Install ","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"kr3517niyJ"},{"type":"inlineCode","value":"uv","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"zoHQYh9AOO"},{"type":"text","value":":","position":{"start":{"line":170,"column":1},"end":{"line":170,"column":1}},"key":"UUMZnKIlFa"}],"key":"UcTkbutiJF"}],"key":"KmsFwrlnjC"},{"type":"code","lang":"bash","value":"curl -LsSf https://astral.sh/uv/install.sh | sh\nsource $HOME/.local/bin/env","key":"Wsk8TROqqY"},{"type":"paragraph","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"children":[{"type":"strong","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"children":[{"type":"text","value":"Verify ","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"key":"EOcftKKmSc"},{"type":"inlineCode","value":"uv","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"key":"xXivYQjpqs"},{"type":"text","value":" installation:","position":{"start":{"line":177,"column":1},"end":{"line":177,"column":1}},"key":"qQMjRWkKbD"}],"key":"eu50MLdWeA"}],"key":"nOSxSWLsdO"},{"type":"code","lang":"bash","value":"uv --version","key":"cbdpgUnEjO"},{"type":"heading","depth":2,"position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"children":[{"type":"text","value":"Step 4: Clone the GitHub Repository","position":{"start":{"line":183,"column":1},"end":{"line":183,"column":1}},"key":"H7RS7iykfC"}],"identifier":"step-4-clone-the-github-repository","label":"Step 4: Clone the GitHub Repository","html_id":"step-4-clone-the-github-repository","implicit":true,"key":"x3fn8pRh4b"},{"type":"paragraph","position":{"start":{"line":185,"column":1},"end":{"line":185,"column":1}},"children":[{"type":"text","value":"Clone the GitHub repository containing the ","position":{"start":{"line":185,"column":1},"end":{"line":185,"column":1}},"key":"Bn7B3Wvpic"},{"type":"link","url":"https://github.com/rexsimiloluwah/finetuning-gemma-1b-aims-gcp-tutorial.git","position":{"start":{"line":185,"column":1},"end":{"line":185,"column":1}},"children":[{"type":"text","value":"code","position":{"start":{"line":185,"column":1},"end":{"line":185,"column":1}},"key":"VnnikZg47E"}],"urlSource":"https://github.com/rexsimiloluwah/finetuning-gemma-1b-aims-gcp-tutorial.git","error":true,"key":"S2De5MrDK7"},{"type":"text","value":" for this hands-on session into your VM:","position":{"start":{"line":185,"column":1},"end":{"line":185,"column":1}},"key":"QLozQu7gwH"}],"key":"adHWMKFfLM"},{"type":"code","lang":"bash","value":"git clone https://github.com/rexsimiloluwah/finetuning-gemma-1b-aims-gcp-tutorial.git\ncd finetuning-gemma-1b-aims-gcp-tutorial","key":"DVacsisI9Z"},{"type":"heading","depth":2,"position":{"start":{"line":192,"column":1},"end":{"line":192,"column":1}},"children":[{"type":"text","value":"Step 5: Set Up the Python Environment","position":{"start":{"line":192,"column":1},"end":{"line":192,"column":1}},"key":"cyE5b1g15D"}],"identifier":"step-5-set-up-the-python-environment","label":"Step 5: Set Up the Python Environment","html_id":"step-5-set-up-the-python-environment","implicit":true,"key":"feaEtD6aGL"},{"type":"paragraph","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"To setup the Python virtual environment using ","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"gv1gW79nre"},{"type":"inlineCode","value":"uv","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"iqwyslOw8j"},{"type":"text","value":":","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"mSfh9OOdP6"}],"key":"muM9UCaYTO"},{"type":"code","lang":"bash","value":"uv venv --python 3.12\nuv sync","key":"VRHvX5hUhT"},{"type":"paragraph","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"children":[{"type":"inlineCode","value":"uv sync","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"key":"gBFfaHp6SD"},{"type":"text","value":" reads the ","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"key":"eaXZlM9lem"},{"type":"inlineCode","value":"uv.lock","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"key":"SEbpPltDaF"},{"type":"text","value":" file and installs all dependencies at the exact versions used during development, ensuring the environment on the VM is identical to what was used locally.","position":{"start":{"line":201,"column":1},"end":{"line":201,"column":1}},"key":"lp57TeLfQK"}],"key":"KNwx9FWC46"},{"type":"heading","depth":2,"position":{"start":{"line":203,"column":1},"end":{"line":203,"column":1}},"children":[{"type":"text","value":"Step 6: Configure Environment Variables","position":{"start":{"line":203,"column":1},"end":{"line":203,"column":1}},"key":"IK8J6fO9Y3"}],"identifier":"step-6-configure-environment-variables","label":"Step 6: Configure Environment Variables","html_id":"step-6-configure-environment-variables","implicit":true,"key":"QFpbEdOuLW"},{"type":"paragraph","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"children":[{"type":"text","value":"You need two API keys before running anything in this hands-on session: a ","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"TlQwxo9usK"},{"type":"strong","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"children":[{"type":"text","value":"HuggingFace API token","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"lt4hr2sxxH"}],"key":"hG7u1IhpfW"},{"type":"text","value":" to access the Gemma model and a ","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"FSNOILa9SZ"},{"type":"strong","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"children":[{"type":"text","value":"Weights & Biases API key","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"XiaawmPCXQ"}],"key":"R3k2k70prg"},{"type":"text","value":" to access the WandB platform for experiment tracking.","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"xJBx1FsCRv"}],"key":"SMT40DxoTi"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Getting your WandB API key:","position":{"start":{"line":208,"column":1},"end":{"line":208,"column":1}},"key":"mYxqLU5yBl"}],"key":"nlBfuT9wvM"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":210,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Go to ","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"CqheNPbEOu"},{"type":"link","url":"http://wandb.ai","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"children":[{"type":"text","value":"wandb.ai","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"el1ecQyQen"}],"urlSource":"http://wandb.ai","key":"TSeEftJ1EN"},{"type":"text","value":" and create a free account if you don’t have one","position":{"start":{"line":210,"column":1},"end":{"line":210,"column":1}},"key":"qhQntQp9xS"}],"key":"x0g6BmoFOx"}],"key":"qrYwwYbHnq"},{"type":"listItem","spread":true,"position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Once logged in, click Create a new project and give it a name, for example ","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"MbybTFFOmt"},{"type":"inlineCode","value":"gemma-finetuning-gcp","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"gg5m3cEQ9P"},{"type":"text","value":". This is where all your training runs and metrics will be logged.","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"uzlHHfhv4S"}],"key":"JIJAWDv37a"}],"key":"WUW75fu1kU"},{"type":"listItem","spread":true,"position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Navigate to ","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"key":"IrODLX8zdf"},{"type":"link","url":"http://wandb.ai/authorize","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"children":[{"type":"text","value":"wandb.ai/authorize","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"key":"nJNjw3ZP0r"}],"urlSource":"http://wandb.ai/authorize","key":"Orv2Iglqmx"}],"key":"tUq2kPMV0N"}],"key":"r12KMF7qUG"},{"type":"listItem","spread":true,"position":{"start":{"line":213,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Copy your API key","position":{"start":{"line":213,"column":1},"end":{"line":213,"column":1}},"key":"Bc7WasPXO9"}],"key":"p1eOaEnOrE"}],"key":"wY4rlS9NyN"}],"key":"Rbyjs33J5d"}],"key":"uwzhAwzGuk"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/create_new_project_w-1654c90f25a039c9cd3dea119a07f7d2.png","alt":"Create new project in WandB","align":"center","key":"QX6OKAPJqj","urlSource":"./images/create_new_project_wandb.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":220,"column":1},"end":{"line":220,"column":1}},"children":[{"type":"text","value":"Screenshot of “Create a new project” step in WandB","position":{"start":{"line":220,"column":1},"end":{"line":220,"column":1}},"key":"wZjplIgJi2"}],"key":"iTMVqqVDNb"}],"key":"vmXCvIIyCY"}],"enumerator":"1","key":"AezKbZV6UG"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Getting your HuggingFace token","position":{"start":{"line":224,"column":1},"end":{"line":224,"column":1}},"key":"aIG2fZdWFe"}],"key":"n1FxdEovC3"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":226,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Go to ","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"ISbtGlZvGR"},{"type":"link","url":"https://huggingface.co","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"children":[{"type":"text","value":"huggingface.co","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"sjmH9PEGbq"}],"urlSource":"https://huggingface.co","key":"XGtjVq9U9k"},{"type":"text","value":" and create a free account if you don’t have one","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"S3o5KkycWe"}],"key":"vjthIaheWz"}],"key":"Mzp5PmH4bf"},{"type":"listItem","spread":true,"position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Navigate to ","position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"key":"ZfMm5wwtQe"},{"type":"link","url":"https://huggingface.co/settings/tokens","position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"children":[{"type":"text","value":"huggingface​.co​/settings​/tokens","position":{"start":{"line":227,"column":1},"end":{"line":227,"column":1}},"key":"XZcExJRQes"}],"urlSource":"https://huggingface.co/settings/tokens","key":"wvWFdl320w"}],"key":"PQTnY2WZrd"}],"key":"Mns8nI7gRL"},{"type":"listItem","spread":true,"position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a new token with read permissions and copy it","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"OkBzYIah9k"}],"key":"kyU4uDnOVf"}],"key":"eRAabWBg3v"}],"key":"dfLevjzQgd"}],"key":"YV6l9rwgiW"},{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Warning","key":"xGsS6oO7w8"}],"key":"fj7KK2FaLs"},{"type":"paragraph","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"children":[{"type":"text","value":"Gemma 3 is a gated model on HuggingFace. Before your token will work, you must visit ","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"NkMrNkgzSc"},{"type":"link","url":"http://huggingface.co/google/gemma-3-1b-it","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"children":[{"type":"text","value":"huggingface​.co​/google​/gemma​-3​-1b​-it","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"OT9C2c76mg"}],"urlSource":"http://huggingface.co/google/gemma-3-1b-it","key":"e7K5mXPH4H"},{"type":"text","value":" and accept the license agreement. Without this step, the training script will fail with a 401 error.","position":{"start":{"line":232,"column":1},"end":{"line":232,"column":1}},"key":"Oun4NUE84W"}],"key":"MeRyRYWT1s"}],"key":"DR8qLsAwOK"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/huggingface_gemma3_1-ee71567e68433b6f16b5ee53fa51f0e0.png","alt":"Accept Gemma 3 1B License Agreement on HuggingFace","align":"center","key":"ER8M5pHiGK","urlSource":"./images/huggingface_gemma3_1b_license_agreement.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":239,"column":1},"end":{"line":239,"column":1}},"children":[{"type":"text","value":"Screenshot of “Accept Gemma 3 1B License Agreement on HuggingFace” step","position":{"start":{"line":239,"column":1},"end":{"line":239,"column":1}},"key":"d8MygO9UiR"}],"key":"usuZNUnCUK"}],"key":"PxeG7OVA68"}],"enumerator":"2","key":"bFvgUw8T6U"},{"type":"paragraph","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"children":[{"type":"text","value":"Now copy the example env file ","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"gv7eKfv0W0"},{"type":"inlineCode","value":".env.example","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"wPFp6B0RQG"},{"type":"text","value":" to create your ","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"tQfDW3u6kZ"},{"type":"inlineCode","value":".env","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"ZSpL5Gvht4"},{"type":"text","value":" file and fill in your credentials:","position":{"start":{"line":242,"column":1},"end":{"line":242,"column":1}},"key":"ActvHCW7HX"}],"key":"VRgrIdUUFe"},{"type":"code","lang":"bash","value":"cp .env.example .env\nnano .env","key":"UOskngof8C"},{"type":"paragraph","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"children":[{"type":"text","value":"Fill in your values:","position":{"start":{"line":249,"column":1},"end":{"line":249,"column":1}},"key":"SQoxBDigh5"}],"key":"doxEO45PSz"},{"type":"code","lang":"bash","value":"HF_TOKEN=your_huggingface_token\nWANDB_API_KEY=your_wandb_api_key\nWANDB_PROJECT=your_wandb_project_name","key":"RN2vWCkK5M"},{"type":"paragraph","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"children":[{"type":"text","value":"To exit the ","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"ZZ9Pt7xRsl"},{"type":"inlineCode","value":"nano","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"qPGI7jSVnk"},{"type":"text","value":" editor: press ","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"f9AZHVRHLM"},{"type":"inlineCode","value":"Ctrl+O","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"Gea2hsyEQp"},{"type":"text","value":" then ","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"Be1IKTT9bw"},{"type":"inlineCode","value":"Enter","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"KU91UJOACc"},{"type":"text","value":" to save, then ","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"d5NiVMyZNl"},{"type":"inlineCode","value":"Ctrl+X","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"QiMyBQRlHl"}],"key":"UtUMWjv5HG"},{"type":"admonition","kind":"important","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Before moving on, please confirm the following:","position":{"start":{"line":259,"column":1},"end":{"line":259,"column":1}},"key":"YU9ykm6zOG"}],"key":"MAUtu7jGcP"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":261,"column":1},"end":{"line":265,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":261,"column":1},"end":{"line":261,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Created a WandB account and a new project","position":{"start":{"line":261,"column":1},"end":{"line":261,"column":1}},"key":"ezMEyX71Yk"}],"key":"HR4NFJltbO"}],"checked":false,"key":"aMjeymw893"},{"type":"listItem","spread":true,"position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Copied your WandB API key from ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"kjAA6LwNCL"},{"type":"link","url":"http://wandb.ai/authorize","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"children":[{"type":"text","value":"wandb.ai/authorize","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"QnbudnmBuk"}],"urlSource":"http://wandb.ai/authorize","key":"zZ7JwagIqS"}],"key":"X10u7Ib7Ap"}],"checked":false,"key":"BtewNcppLr"},{"type":"listItem","spread":true,"position":{"start":{"line":263,"column":1},"end":{"line":263,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Created a HuggingFace account and generated a read token","position":{"start":{"line":263,"column":1},"end":{"line":263,"column":1}},"key":"hLT4z1uX8A"}],"key":"lDgEIPMGqA"}],"checked":false,"key":"L6rmXF5G1v"},{"type":"listItem","spread":true,"position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Accepted the Gemma 3 license agreement at ","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"key":"wYf0GD2XTH"},{"type":"link","url":"http://huggingface.co/google/gemma-3-1b-it","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"children":[{"type":"text","value":"huggingface​.co​/google​/gemma​-3​-1b​-it","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"key":"x2OJJ5nvv2"}],"urlSource":"http://huggingface.co/google/gemma-3-1b-it","key":"NrjJqtXAgv"}],"key":"l2MqzuEM19"}],"checked":false,"key":"iddaH94HgB"},{"type":"listItem","spread":true,"position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Filled in ","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"WC5bnUftng"},{"type":"inlineCode","value":".env","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"jj1FoaXRDo"},{"type":"text","value":" file with your ","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"d7rEdJRCci"},{"type":"inlineCode","value":"HF_TOKEN","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"oznzJzgNOs"},{"type":"text","value":", ","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"DW1JZc6fDN"},{"type":"inlineCode","value":"WANDB_API_KEY","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"p5RiQYQp5Y"},{"type":"text","value":", and ","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"q6AdJZ4HXM"},{"type":"inlineCode","value":"WANDB_PROJECT","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"eQWuTlsKoa"}],"key":"nZ1i9EGpwN"}],"checked":false,"key":"pUczD8xg6I"}],"key":"PownR6ykmT"}],"key":"aXn85VLKyP"},{"type":"heading","depth":2,"position":{"start":{"line":268,"column":1},"end":{"line":268,"column":1}},"children":[{"type":"text","value":"Step 7: Upload the Dataset to Google Cloud Storage (GCS) Bucket (Optional)","position":{"start":{"line":268,"column":1},"end":{"line":268,"column":1}},"key":"mAHAka0G8h"}],"identifier":"step-7-upload-the-dataset-to-google-cloud-storage-gcs-bucket-optional","label":"Step 7: Upload the Dataset to Google Cloud Storage (GCS) Bucket (Optional)","html_id":"step-7-upload-the-dataset-to-google-cloud-storage-gcs-bucket-optional","implicit":true,"key":"WrgOg1kjZh"},{"type":"paragraph","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"children":[{"type":"text","value":"Rather than downloading the dataset from HuggingFace every time you run an experiment, we upload it once to GCS (GCP’s scalable cloud object storage service) and read from there in all subsequent runs. This is faster, avoids rate limits, and means your experiment does not depend on an external service being available. On real projects with large datasets, this pattern becomes essential.","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"FO1DxOWJhh"}],"key":"M3GyvN6G3H"},{"type":"paragraph","position":{"start":{"line":272,"column":1},"end":{"line":272,"column":1}},"children":[{"type":"strong","position":{"start":{"line":272,"column":1},"end":{"line":272,"column":1}},"children":[{"type":"text","value":"Run the upload script:","position":{"start":{"line":272,"column":1},"end":{"line":272,"column":1}},"key":"RpHohIa8Kk"}],"key":"U9bs41My9f"}],"key":"losOYRN74L"},{"type":"code","lang":"bash","value":"uv run bash scripts/download_and_upload_gcs.sh\n\n# You can optionally pass a custom bucket name:\nuv run bash scripts/download_and_upload_gcs.sh <BUCKET_NAME>","key":"HoXqogte9c"},{"type":"paragraph","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"children":[{"type":"text","value":"This script downloads the Dolly-15k dataset from HuggingFace, creates a new GCS bucket, and uploads the downloaded dataset to the GCS bucket.","position":{"start":{"line":281,"column":1},"end":{"line":281,"column":1}},"key":"Sie8R29gOe"}],"key":"dkJxFHoeuI"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/upload_dataset_to_gc-1c4c0672a23d919c324d250e9becc632.png","alt":"Upload Dataset to GCS Instruction","align":"center","key":"ZDcunQ86NR","urlSource":"./images/upload_dataset_to_gcs_bucket.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"children":[{"type":"text","value":"Screenshot of “Upload Dataset to GCS Bucket” step","position":{"start":{"line":287,"column":1},"end":{"line":287,"column":1}},"key":"SRQV0gqPLL"}],"key":"mIAsF3fpTJ"}],"key":"oKeogEA7Ud"}],"enumerator":"3","key":"jeWBPmLLIr"},{"type":"paragraph","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"children":[{"type":"strong","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"children":[{"type":"text","value":"Verify the data is in the GCS bucket:","position":{"start":{"line":290,"column":1},"end":{"line":290,"column":1}},"key":"lOgUOVM24U"}],"key":"TjLUXL88ym"}],"key":"kZNsET8zu3"},{"type":"code","lang":"bash","value":"gcloud storage ls gs://<BUCKET_NAME>/data/raw/","key":"xhFYwkUusq"},{"type":"heading","depth":2,"position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"children":[{"type":"text","value":"Step 8: Start a ","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"key":"QPVaULjHNH"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"key":"k2us5cNZq3"},{"type":"text","value":" Session","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"key":"IsuzczDLx1"}],"identifier":"step-8-start-a-tmux-session","label":"Step 8: Start a tmux Session","html_id":"step-8-start-a-tmux-session","implicit":true,"key":"XQ4nQAZQQv"},{"type":"paragraph","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"children":[{"type":"text","value":"Training this 1 Billion parameter model using LoRA takes about 25-40 minutes. Rather than keeping your SSH connection open the entire time, we use ","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"key":"WYKGwWSI49"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"key":"iyfGNHbzyS"},{"type":"text","value":" to run training in a persistent terminal session. This means if your SSH connection closes, training keeps running on the VM.","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"key":"gCYbUhlZ0F"}],"key":"m4bzUlkGEe"},{"type":"paragraph","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"strong","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"text","value":"Install ","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"r7Ej5WT2WX"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"lW3ee37P6F"},{"type":"text","value":" and start a new session:","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"ojjYp82yRq"}],"key":"XQsx3r002V"}],"key":"Sbh4MgChV0"},{"type":"code","lang":"bash","value":"sudo apt-get install -y tmux \ntmux new -s finetunegemma1b","key":"xuvr5pyoyL"},{"type":"paragraph","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"children":[{"type":"text","value":"This creates a new session named “finetunegemma1b”. You should now be inside the created ","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"key":"qfQ2g3MuPQ"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"key":"wdJerXTSDR"},{"type":"text","value":" session.","position":{"start":{"line":307,"column":1},"end":{"line":307,"column":1}},"key":"PeRZVeJspM"}],"key":"W0NRzrZmtx"},{"type":"paragraph","position":{"start":{"line":309,"column":1},"end":{"line":309,"column":1}},"children":[{"type":"strong","position":{"start":{"line":309,"column":1},"end":{"line":309,"column":1}},"children":[{"type":"text","value":"To detach the session without killing it:","position":{"start":{"line":309,"column":1},"end":{"line":309,"column":1}},"key":"br9PEm0psF"}],"key":"Aec8RzyJQP"}],"key":"MTvrkhfqW9"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":311,"column":1},"end":{"line":312,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":311,"column":1},"end":{"line":312,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Press ","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"Z6cOYIvoJb"},{"type":"inlineCode","value":"Ctrl+B","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"WnqVPx5Zda"},{"type":"text","value":" then the ","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"Dl5BkE9ufK"},{"type":"inlineCode","value":"D","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"gKj6dP9UCA"},{"type":"text","value":" key","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"TO4qeSziRT"}],"key":"snaCNDfqSD"}],"key":"iysoL6eWgd"}],"key":"Ka8LCfWzns"},{"type":"paragraph","position":{"start":{"line":313,"column":1},"end":{"line":313,"column":1}},"children":[{"type":"text","value":"Alternatively, you can run the command from another shell for this server:","position":{"start":{"line":313,"column":1},"end":{"line":313,"column":1}},"key":"hBqUoc6F4l"}],"key":"eG5INiYTbz"},{"type":"code","lang":"bash","value":"tmux detach -s <session_name>","key":"tG2x86HpWE"},{"type":"paragraph","position":{"start":{"line":319,"column":1},"end":{"line":319,"column":1}},"children":[{"type":"strong","position":{"start":{"line":319,"column":1},"end":{"line":319,"column":1}},"children":[{"type":"text","value":"To return to a detached session layer:","position":{"start":{"line":319,"column":1},"end":{"line":319,"column":1}},"key":"fFN6ay05Ba"}],"key":"PM030mG7BY"}],"key":"bAhZ3as2fj"},{"type":"code","lang":"bash","value":"tmux attach -t <session_name>","key":"FFVvluMdv0"},{"type":"heading","depth":2,"position":{"start":{"line":325,"column":1},"end":{"line":325,"column":1}},"children":[{"type":"text","value":"Step 9: Run the Training Script","position":{"start":{"line":325,"column":1},"end":{"line":325,"column":1}},"key":"M2tLJn4QbT"}],"identifier":"step-9-run-the-training-script","label":"Step 9: Run the Training Script","html_id":"step-9-run-the-training-script","implicit":true,"key":"Dlg6s1ykVf"},{"type":"paragraph","position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"children":[{"type":"text","value":"In the ","position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"key":"OMpoYfjX1q"},{"type":"inlineCode","value":"tmux","position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"key":"zseFUj1HAm"},{"type":"text","value":" session shell, run the script below to start finetuning the model:","position":{"start":{"line":327,"column":1},"end":{"line":327,"column":1}},"key":"AEHEr2TEbE"}],"key":"xJeUPpTPAd"},{"type":"code","lang":"bash","value":"uv run python -m scripts.run_train \\\n    data.source=hf \\\n    data.max_train_samples=10000 \\\n    training.num_epochs=2 \\\n    training.batch_size=8 \\\n    experiment_id=exp_lora_r8","key":"c7NROEtf5u"},{"type":"paragraph","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"children":[{"type":"text","value":"This trains on 10,000 samples for 2 epochs with LoRA rank 8, giving us ","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"D7OozUuPDS"},{"type":"inlineCode","value":"10,000 / 8 = 1,250 steps per epoch","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"ZlNuVBNodo"},{"type":"text","value":" and ","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"dQ1VArgggN"},{"type":"inlineCode","value":"2,500 steps total","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"IqOrLGH2Oy"},{"type":"text","value":". On the NVIDIA L4 GPU, this should take roughly ","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"hOKzuKd0zE"},{"type":"strong","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"children":[{"type":"text","value":"20-30 minutes","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"c2UUt7KLq6"}],"key":"D0KYJ3siO0"},{"type":"text","value":".","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"VGUW08L1wZ"}],"key":"nvIvngFrzG"},{"type":"paragraph","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"text","value":"You can now detach from the tmux session and monitor training progress from your WandB dashboard at ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"KB0CsVTBuM"},{"type":"link","url":"http://wandb.ai","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"text","value":"wandb.ai","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"YmWtLSKUWl"}],"urlSource":"http://wandb.ai","key":"UVSVPIy3kv"},{"type":"text","value":". You will see ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"BU3cwFwcM2"},{"type":"inlineCode","value":"train/loss","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"r5i6CHbcx2"},{"type":"text","value":", ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"SbnxlrhnKe"},{"type":"inlineCode","value":"eval/loss","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"K73vP610kf"},{"type":"text","value":", ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"usiStRQw9Y"},{"type":"inlineCode","value":"train/grad_norm","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"KGLcyz5irH"},{"type":"text","value":", and ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"dmUOy80P0f"},{"type":"inlineCode","value":"train/learning_rate","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"ByRzNumGpx"},{"type":"text","value":" updating every 10 steps.","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"cCZQB8wnhQ"}],"key":"wRRz35n87v"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/wandb_train_run_moni-d9513b093be2be748f08d600ac115a2d.png","alt":"Monitor Training Progress on WandB Dashboard","align":"center","key":"cAVuZDzmpe","urlSource":"./images/wandb_train_run_monitoring.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"children":[{"type":"text","value":"Screenshot of WandB dashboard for monitoring training progress and metrics","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"IGQItEaLc5"}],"key":"efZIneTFZo"}],"key":"t2T6TtGuaq"}],"enumerator":"4","key":"WQRIh9LRfR"},{"type":"heading","depth":2,"position":{"start":{"line":349,"column":1},"end":{"line":349,"column":1}},"children":[{"type":"text","value":"Step 10: Run Evaluation","position":{"start":{"line":349,"column":1},"end":{"line":349,"column":1}},"key":"dBcnqvp1aK"}],"identifier":"step-10-run-evaluation","label":"Step 10: Run Evaluation","html_id":"step-10-run-evaluation","implicit":true,"key":"ZsojRJCBXG"},{"type":"paragraph","position":{"start":{"line":351,"column":1},"end":{"line":351,"column":1}},"children":[{"type":"text","value":"Once training finishes, reattach to the tmux session if you detached:","position":{"start":{"line":351,"column":1},"end":{"line":351,"column":1}},"key":"bkBRmsnUsI"}],"key":"j7ty6nHaYf"},{"type":"code","lang":"bash","value":"tmux attach -t <session_name>","key":"MG1UVfU5mD"},{"type":"paragraph","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"children":[{"type":"text","value":"Run the evaluation script. Replace ","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"qRqbqnTogA"},{"type":"inlineCode","value":"<experiment_id>","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"Qh9O4cmmk3"},{"type":"text","value":" and ","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"WDz1XsF751"},{"type":"inlineCode","value":"<checkpoint_folder>","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"JZaz03xWZ4"},{"type":"text","value":" with the actual paths from your ","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"pvN93U6WV9"},{"type":"inlineCode","value":"outputs/","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"ZvBh8BsmPY"},{"type":"text","value":" directory:","position":{"start":{"line":357,"column":1},"end":{"line":357,"column":1}},"key":"qaB6z3VnNK"}],"key":"Wvy6efvCNq"},{"type":"code","lang":"bash","value":"uv run python -m scripts.run_evaluate \\\n    --model_path outputs/<experiment_id>/<checkpoint_folder> \\\n    --eval_file data/eval/eval_prompts.jsonl","key":"i3CDeMyBGs"},{"type":"paragraph","position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"children":[{"type":"text","value":"This computes perplexity and repetition rate on the evaluation set and logs the results to WandB.","position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"key":"MQB7DeuVVG"}],"key":"SjEVMjrWCb"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/wandb-gemma-finetune-70f513af0da097c4e19e18407574d1d2.png","alt":"Monitor Evaluation Results on WandB Dashboard","align":"center","key":"yHye5PG1RT","urlSource":"./images/wandb-gemma-finetune-evaluation-dashboard.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"children":[{"type":"text","value":"Screenshot of WandB dashboard for monitoring evaluation results","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"key":"n4CPJUiGoc"}],"key":"oy0Kl6lgiy"}],"key":"ZPUbNYdeUJ"}],"enumerator":"5","key":"Fyk4YEz1er"},{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"JKSCLsXBFK"}],"key":"k2Lce6uktX"},{"type":"paragraph","position":{"start":{"line":375,"column":1},"end":{"line":375,"column":1}},"children":[{"type":"text","value":"Do not worry too much about the evaluation results. The goal of this tutorial is not to produce a state-of-the-art model but to walk through the complete workflow of fine-tuning a large language model on a GCP VM end to end.","position":{"start":{"line":375,"column":1},"end":{"line":375,"column":1}},"key":"lF7kOPNlwo"}],"key":"lXlhrASmB0"}],"key":"FD3LXe31Qo"},{"type":"heading","depth":2,"position":{"start":{"line":378,"column":1},"end":{"line":378,"column":1}},"children":[{"type":"text","value":"Step 11: Run Inference (Optional)","position":{"start":{"line":378,"column":1},"end":{"line":378,"column":1}},"key":"IpoKBYv0Jd"}],"identifier":"step-11-run-inference-optional","label":"Step 11: Run Inference (Optional)","html_id":"step-11-run-inference-optional","implicit":true,"key":"ChdGPm8vaY"},{"type":"paragraph","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"children":[{"type":"text","value":"Test the model on a single instruction","position":{"start":{"line":380,"column":1},"end":{"line":380,"column":1}},"key":"eh3ObWvBxA"}],"key":"XzXrAnzs5E"},{"type":"code","lang":"bash","value":"uv run python -m scripts.run_inference \\\n    --model_path outputs/<experiment_id>/<checkpoint_folder> \\\n    --instruction \"Explain what machine learning is in simple terms\"","key":"Cmp3RRM66n"},{"type":"paragraph","position":{"start":{"line":388,"column":1},"end":{"line":388,"column":1}},"children":[{"type":"text","value":"You can also run in interactive mode to keep sending instructions:","position":{"start":{"line":388,"column":1},"end":{"line":388,"column":1}},"key":"qLDQjjLrSf"}],"key":"rwYlCXlBoW"},{"type":"code","lang":"bash","value":"uv run python -m scripts.run_inference \\\n    --model_path outputs/<experiment_id>/<checkpoint_folder>","key":"N91lGbSiOM"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/finetune_gemma_exper-cf7403e231458495aec5fd5c88230054.png","alt":"Fine-tuned Gemma 3 1B Inference Result","align":"center","key":"h0OGJ0XjU0","urlSource":"./images/finetune_gemma_experiment_inference_result.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":398,"column":1},"end":{"line":398,"column":1}},"children":[{"type":"text","value":"Screenshot of inference result using the fine-tuned Gemma 3 1B model","position":{"start":{"line":398,"column":1},"end":{"line":398,"column":1}},"key":"ZEPqGv5xmr"}],"key":"aLhuO2ADOl"}],"key":"gZCi7oGW3q"}],"enumerator":"6","key":"Mu6r79RTPt"},{"type":"heading","depth":2,"position":{"start":{"line":401,"column":1},"end":{"line":401,"column":1}},"children":[{"type":"text","value":"Step 12: Sync Outputs to GCS","position":{"start":{"line":401,"column":1},"end":{"line":401,"column":1}},"key":"wxMHdJeNcZ"}],"identifier":"step-12-sync-outputs-to-gcs","label":"Step 12: Sync Outputs to GCS","html_id":"step-12-sync-outputs-to-gcs","implicit":true,"key":"aKOkcC9Tr7"},{"type":"paragraph","position":{"start":{"line":403,"column":1},"end":{"line":403,"column":1}},"children":[{"type":"text","value":"Before deleting the VM, sync your checkpoints and logs to your GCS bucket so they persist:","position":{"start":{"line":403,"column":1},"end":{"line":403,"column":1}},"key":"Mgq72lHW8g"}],"key":"KFkQm7Gs74"},{"type":"code","lang":"bash","value":"gcloud storage cp -r outputs/ gs://<BUCKET_NAME>/outputs/","key":"E5KLtjiJD5"},{"type":"paragraph","position":{"start":{"line":409,"column":1},"end":{"line":409,"column":1}},"children":[{"type":"text","value":"Verify the GCS bucket content from the GCS dashboard or from the CLI:","position":{"start":{"line":409,"column":1},"end":{"line":409,"column":1}},"key":"UFrc9qAboy"}],"key":"I5I838NS66"},{"type":"container","kind":"figure","children":[{"type":"image","url":"/build/gcp-console-gemma-fi-dec315e8d196ce2cd42bfc23d554686c.png","alt":"GCS Bucket on GCP Console","align":"center","key":"A46zJGtgrg","urlSource":"./images/gcp-console-gemma-finetune-experiment-bucket.png"},{"type":"caption","children":[{"type":"paragraph","position":{"start":{"line":415,"column":1},"end":{"line":415,"column":1}},"children":[{"type":"text","value":"Screenshot of GCS bucket on the GCP console showing the “data” and synced “outputs” folder.","position":{"start":{"line":415,"column":1},"end":{"line":415,"column":1}},"key":"PbKhXpoBtl"}],"key":"myPHFaY6gj"}],"key":"py20CwgcoN"}],"enumerator":"7","key":"dF2WEXxQNO"},{"type":"code","lang":"bash","value":"gcloud storage ls gs://<BUCKET_NAME>/outputs/","key":"S0339qVzKF"},{"type":"paragraph","position":{"start":{"line":422,"column":1},"end":{"line":422,"column":1}},"children":[{"type":"text","value":"Exit the tmux session:","position":{"start":{"line":422,"column":1},"end":{"line":422,"column":1}},"key":"ElNvbrox3H"}],"key":"QKhfGbYFiD"},{"type":"code","value":"exit","key":"drKfoU2riE"},{"type":"heading","depth":2,"position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"children":[{"type":"text","value":"Step 13: Resource Cleanup","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"key":"PhSJas4mGi"}],"identifier":"step-13-resource-cleanup","label":"Step 13: Resource Cleanup","html_id":"step-13-resource-cleanup","implicit":true,"key":"GQ1Y2dIGAQ"},{"type":"admonition","kind":"danger","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Danger","key":"t8ASX8zwqD"}],"key":"Flp8gC6NqS"},{"type":"paragraph","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"children":[{"type":"text","value":"Delete the VM when you are done to avoid incurring charges. GPU VMs are billed by the second and the NVIDIA L4 GPU VM using the ","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"aaFb1aXWxl"},{"type":"inlineCode","value":"g2-standard-4","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"xLAzksxVYd"},{"type":"text","value":" machine configuration costs roughly $0.70/hour even when idle.","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"Xc02TU4Brk"}],"key":"T5cFJcmF7Y"}],"key":"Qg7pPOY0xQ"},{"type":"paragraph","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"children":[{"type":"text","value":"Run the script below and replace ","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"key":"lw6D27j9R7"},{"type":"inlineCode","value":"<YOUR_AIMSUSERNAME>","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"key":"AsTAdzHtvt"},{"type":"text","value":" and ","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"key":"Z6mBukQlHK"},{"type":"inlineCode","value":"<ZONE>","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"key":"ZZeUMAp7xV"},{"type":"text","value":" with the values you used in the VM creation script.","position":{"start":{"line":434,"column":1},"end":{"line":434,"column":1}},"key":"UsuxgwYGNk"}],"key":"aSx5wL9sBk"},{"type":"code","lang":"bash","value":"gcloud compute instances delete <YOUR_AIMSUSERNAME>-l4-vm --zone=<ZONE> --quiet","key":"HOwmc0sbsl"},{"type":"paragraph","position":{"start":{"line":440,"column":1},"end":{"line":440,"column":1}},"children":[{"type":"strong","position":{"start":{"line":440,"column":1},"end":{"line":440,"column":1}},"children":[{"type":"text","value":"Verify it has been deleted:","position":{"start":{"line":440,"column":1},"end":{"line":440,"column":1}},"key":"OgIAiCeXGv"}],"key":"y9GVFGshlM"}],"key":"KnqyTsH5r3"},{"type":"code","lang":"bash","value":"gcloud compute instances list","key":"yvjUUAGd8B"},{"type":"thematicBreak","position":{"start":{"line":446,"column":1},"end":{"line":446,"column":1}},"key":"AeGu6A3SG2"},{"type":"heading","depth":2,"position":{"start":{"line":448,"column":1},"end":{"line":448,"column":1}},"children":[{"type":"text","value":"🔑 Key Takeways","position":{"start":{"line":448,"column":1},"end":{"line":448,"column":1}},"key":"yxSlEBVuWu"}],"identifier":"id-key-takeways","label":"🔑 Key Takeways","html_id":"id-key-takeways","implicit":true,"key":"J4eLGawOZC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":450,"column":1},"end":{"line":456,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Using a package manager like ","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"NI6pMLCjuG"},{"type":"inlineCode","value":"uv","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"sve0DbqZYW"},{"type":"text","value":" ensures your Python environment is reproducible across any machine. A single ","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"wekez4cxbs"},{"type":"inlineCode","value":"uv sync","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"uBsf6nAa2R"},{"type":"text","value":" installs all dependencies at the exact versions pinned in the lock file, eliminating environment mismatch issues.","position":{"start":{"line":450,"column":1},"end":{"line":450,"column":1}},"key":"F4HTtrJy65"}],"key":"mHyzgUxgYV"}],"key":"bNQWhV55zV"},{"type":"listItem","spread":true,"position":{"start":{"line":451,"column":1},"end":{"line":451,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Uploading your dataset to GCS once and reading from there on every run is more reliable and faster than downloading from external sources each time.","position":{"start":{"line":451,"column":1},"end":{"line":451,"column":1}},"key":"t0auakqS5Q"}],"key":"R2dDM2MvIR"}],"key":"AbTDp6eAI4"},{"type":"listItem","spread":true,"position":{"start":{"line":452,"column":1},"end":{"line":452,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"tmux","position":{"start":{"line":452,"column":1},"end":{"line":452,"column":1}},"key":"L3WKesXkFA"},{"type":"text","value":" is essential for long-running jobs on remote VMs. It keeps your process alive even if your SSH connection is destroyed.","position":{"start":{"line":452,"column":1},"end":{"line":452,"column":1}},"key":"erUX9EKnZ7"}],"key":"mJz3xleHrj"}],"key":"id9HRwiMc9"},{"type":"listItem","spread":true,"position":{"start":{"line":453,"column":1},"end":{"line":453,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"WandB gives you full visibility into training progress and metrics from any browser, without needing to stay connected to the VM.","position":{"start":{"line":453,"column":1},"end":{"line":453,"column":1}},"key":"S5wNy37sWS"}],"key":"y9CEwSl40F"}],"key":"SwqIWpNjry"},{"type":"listItem","spread":true,"position":{"start":{"line":454,"column":1},"end":{"line":454,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Always sync outputs to GCS before deleting your VM. VM disks are ephemeral and deleted with the instance.","position":{"start":{"line":454,"column":1},"end":{"line":454,"column":1}},"key":"yd4FuyceRe"}],"key":"XrgPFhtdc7"}],"key":"H4CrMZmB5w"},{"type":"listItem","spread":true,"position":{"start":{"line":455,"column":1},"end":{"line":456,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Always delete your VM after a session to avoid unexpected charges.","position":{"start":{"line":455,"column":1},"end":{"line":455,"column":1}},"key":"qJEkN0aYR9"}],"key":"YhZJ9Um2Lw"}],"key":"P3iauAg4Ri"}],"key":"p5DCTtQoDc"},{"type":"heading","depth":2,"position":{"start":{"line":457,"column":1},"end":{"line":457,"column":1}},"children":[{"type":"text","value":"🚀 What’s Next?","position":{"start":{"line":457,"column":1},"end":{"line":457,"column":1}},"key":"ISNthAmzlT"}],"identifier":"id-whats-next","label":"🚀 What’s Next?","html_id":"id-whats-next","implicit":true,"key":"IqQIfX4Wuk"},{"type":"paragraph","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"children":[{"type":"text","value":"In the next session, we will look at ","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"key":"hCAeFupMHd"},{"type":"strong","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"children":[{"type":"text","value":"Vertex AI","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"key":"mIC8SkE4Af"}],"key":"EdJ47dwYCw"},{"type":"text","value":", Google Cloud’s fully managed ML platform and how it can simplify running experiments like this without provisioning or managing any infrastructure yourself.","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"key":"FHDY8q9xRq"}],"key":"TzFVTWvojt"}],"key":"TcRX8UGpIV"}],"key":"s7gFJuLelK"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Introduction","url":"/part2-running-experiments-on-gcp-vms","group":"Part 2 - Running Experiments On GCP VMs"},"next":{"title":"Introduction","url":"/part3-vertex-ai","group":"Part 3 - Vertex AI"}}},"domain":"http://localhost:3000"}